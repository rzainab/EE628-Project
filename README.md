# EE628-Project
# Neural Text Generation
# Introduction
Deep learning methods have recently achieved great empirical success on machine translation, dialogue response generation, summarization, and other text generation tasks. At a high level, the technique has been to train end-to-end neural network models consisting of an encoder model to produce a hidden representation of the source text, followed by a decoder model to generate the target.
# Method
Using deep neural network (RNN, LSTM, VAE) to train a model and using it to generate sample output.
# Dataset
Dataset would be scrapped from reddit using Python Wrapper PRAW.
# Reference
https://research.google.com/seedbank/seed/generate_shakespeare_using_tfkeras
